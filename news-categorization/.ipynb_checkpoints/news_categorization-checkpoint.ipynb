{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lsk2YQJRz0tk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#importing the required libraries\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "layers = keras.layers\n",
    "models = keras.models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lUTev6Jd02iC"
   },
   "source": [
    "This is where we pre - process the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JGsQ55EI0yyT"
   },
   "outputs": [],
   "source": [
    "bbc_data = pd.read_csv('https://storage.googleapis.com/dataset-uploader/bbc/bbc-text.csv') \n",
    "trainSize = int(len(bbc_data)*0.7)\n",
    "\n",
    "#creating the train test data\n",
    "def train_test(data,size):\n",
    "  trainData = data[:size]\n",
    "  testData = data[size:]\n",
    "  return trainData, testData\n",
    "trainX,testX = train_test(bbc_data['text'], trainSize)\n",
    "trainY,testY = train_test(bbc_data['category'], trainSize)\n",
    "catT, catTe = train_test(bbc_data['category'], trainSize)\n",
    "\n",
    "#turning the text into tokens\n",
    "max_words = 1000\n",
    "def tokenizeFunc(inputData):\n",
    "    finalArr = []\n",
    "  for i in inputData.values:\n",
    "    cleaned = i\n",
    "    #i = re.sub('\\W',\"\",i )\n",
    "    i = re.sub(' +', \" \", i)\n",
    "    ##i = re.sub('(?i)\\b[a-z]\\b', \"\", i)\n",
    "    i = i.split(' ')\n",
    "    finalArr.append(i)\n",
    "  return finalArr\n",
    "\n",
    "trX  = tokenizeFunc(trX)\n",
    "tX = tokenizeFunc(tX)\n",
    "\n",
    "word_count = 0\n",
    "wordIndex = dict()\n",
    "indexWord = dict()\n",
    "def wordsToNum(dataDict, indexDict, wordCount, inputArr):\n",
    "    finalArr = []\n",
    "    temparr = []\n",
    "    for i in inputArr:\n",
    "        for j in i:\n",
    "            \n",
    "            if j in dataDict:\n",
    "                j = dataDict[j]\n",
    "                temparr.append(j)\n",
    "            else:\n",
    "                wordCount+=1\n",
    "                dataDict[j] = wordCount\n",
    "                indexDict[wordCount] = j\n",
    "                j = dataDict[j]\n",
    "                temparr.append(j)\n",
    "                \n",
    "        finalArr.append(temparr)\n",
    "        temparr = []\n",
    "    return finalArr\n",
    "\n",
    "def numToBin(indexDict, finalArr):\n",
    "    finalMatrix = []\n",
    "    tempMatrix = [0]\n",
    "    for i in finalArr:\n",
    "        for j in i:\n",
    "            val = indexDict.count(j)\n",
    "            if val > 0:\n",
    "                tempMatrix.append(1)\n",
    "            else:\n",
    "                tempMatrix.append(0)\n",
    "        finalMatrix.append(tempMatrix)\n",
    "        tempMatrix = [0]\n",
    "    return finalMatrix\n",
    "\n",
    "def keyMaxRange(indexDict, max_words):\n",
    "    newArr = []\n",
    "    keys = [*indexDict]\n",
    "    for i in range(1000):\n",
    "        newArr.append(keys[i])\n",
    "    return newArr\n",
    "\n",
    "\n",
    "trX = wordsToNum(wordIndex, indexWord, word_count, trX)\n",
    "tX = wordsToNum(wordIndex, indexWord, word_count, tX)\n",
    "indexes = keyMaxRange(indexWord, max_words)\n",
    "trX = numToBin(indexes, trX)\n",
    "tX = numToBin(indexes, tX)\n",
    "#print(testX[0])\n",
    "#working on the labels to turn into numbered text(Encoding)\n",
    "encode = LabelEncoder()\n",
    "encode.fit(trainY)\n",
    "trainY = encode.transform(trainY)\n",
    "testY = encode.transform(testY)\n",
    "\n",
    "\n",
    "classes = np.max(trainY) + 1\n",
    "trainY = keras.utils.to_categorical(trainY, classes)\n",
    "testY = keras.utils.to_categorical(testY, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JQftTwcI__VW"
   },
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "8rEvr957ABJk",
    "outputId": "cc28f4a6-5703-4a70-e8ef-3ae2cd01e195"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0704 18:04:18.223843 11812 training.py:593] The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1401 samples, validate on 156 samples\n",
      "Epoch 1/3\n",
      "1401/1401 [==============================] - 1s 359us/sample - loss: 0.5842 - acc: 0.8330 - val_loss: 0.2203 - val_acc: 0.9231\n",
      "Epoch 2/3\n",
      "1401/1401 [==============================] - 0s 236us/sample - loss: 0.0451 - acc: 0.9929 - val_loss: 0.1474 - val_acc: 0.9487\n",
      "Epoch 3/3\n",
      "1401/1401 [==============================] - 0s 230us/sample - loss: 0.0329 - acc: 0.9936 - val_loss: 0.1649 - val_acc: 0.9487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e9f0f52898>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tensorflow.keras.Sequential()\n",
    "model.add(layers.Dense(1024, input_shape=(max_words,)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dense(classes))\n",
    "model.add(layers.Activation('softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(trainX, trainY, batch_size = 32, nb_epoch = 3, verbose = 1, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L033EoEnHsJ4"
   },
   "source": [
    "Using the model for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "SO7kiQFjFgpz",
    "outputId": "5a504683-cc60-4ae6-998c-2b432e0f15c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: sport\n",
      "Predicted: sport\n",
      "Actual: sport\n",
      "Predicted: sport\n",
      "Actual: entertainment\n",
      "Predicted: entertainment\n",
      "Actual: business\n",
      "Predicted: business\n"
     ]
    }
   ],
   "source": [
    "#prediction\n",
    "text_labels = encode.classes_ \n",
    "\n",
    "for i in range(4):\n",
    "  prediction = model.predict(np.array([testX[i]]))\n",
    "  predict = text_labels[np.argmax(prediction)]\n",
    "  print(\"Actual: \" + catTe.iloc[i])\n",
    "  print(\"Predicted: \" + predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfjs.converters.save_keras_model(model, 'Practice - Jai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "news-categorization.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
